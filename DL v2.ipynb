{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RandomOgre101/dl-project/blob/main/DL%20v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UGID9C4KjOCV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16, ResNet50, DenseNet121\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uxgPB8-ujOCX"
      },
      "outputs": [],
      "source": [
        "path = './'\n",
        "\n",
        "apple_pie_train = glob.glob(path + 'train/apple_pie/*')\n",
        "apple_pie_test = glob.glob(path + 'test/apple_pie/*')\n",
        "\n",
        "cannoli_train = glob.glob(path + 'train/cannoli/*')\n",
        "cannoli_test = glob.glob(path + 'test/cannoli/*')\n",
        "\n",
        "ramen_train = glob.glob(path + 'train/ramen/*')\n",
        "ramen_test = glob.glob(path + 'test/ramen/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCPMrFfijOCZ",
        "outputId": "440bb5ef-e093-40b5-b2e7-b35b76c343ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analysis by class: \n",
            "\t\tTrain\tTest\n",
            "Apple Pie\t750\t250\n",
            "Cannoli\t\t750\t250\n",
            "Ramen\t\t750\t250\n"
          ]
        }
      ],
      "source": [
        "print(\"Analysis by class: \\n\\t\\tTrain\\tTest\")\n",
        "print(f\"Apple Pie\\t{len(apple_pie_train)}\\t{len(apple_pie_test)}\")\n",
        "print(f\"Cannoli\\t\\t{len(cannoli_train)}\\t{len(cannoli_test)}\")\n",
        "print(f\"Ramen\\t\\t{len(ramen_train)}\\t{len(ramen_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BqU6EyqtyH-G"
      },
      "outputs": [],
      "source": [
        "class_to_category = {\n",
        "     0 : 'apple pie',\n",
        "     1 : 'cannoli',\n",
        "     2 : 'ramen'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXO_7Tf9jOCa",
        "outputId": "dc391344-076c-4ae2-8882-86fb04dcee06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2250 images belonging to 3 classes.\n",
            "Found 750 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(featurewise_center=False,\n",
        "                 samplewise_center=False,\n",
        "                 featurewise_std_normalization=False,\n",
        "                 samplewise_std_normalization=False,\n",
        "                 zca_whitening=False,\n",
        "                 rotation_range=5,\n",
        "                 shear_range=0.2,\n",
        "                 zoom_range=0.2,\n",
        "                 width_shift_range=0.05,\n",
        "                 height_shift_range=0.05,\n",
        "                 channel_shift_range=0.,\n",
        "                 fill_mode='nearest',\n",
        "                 horizontal_flip=True,\n",
        "                 vertical_flip=False,\n",
        "                 rescale=1/255)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        path + 'train/',\n",
        "        target_size=(224,224),\n",
        "        class_mode='categorical',\n",
        "        batch_size=32)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1/255)\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        path + 'test/',\n",
        "        target_size=(224,224),\n",
        "        class_mode='categorical',\n",
        "        batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cSAqsg7BjOCb"
      },
      "outputs": [],
      "source": [
        "def create_model(base_model):\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "    predictions = Dense(3, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model\n",
        "\n",
        "def ensemble(models, model_input):\n",
        "    outputs = [model(model_input) for model in models]\n",
        "    avg = tf.keras.layers.average(outputs)\n",
        "    model = Model(inputs=model_input, outputs=avg, name='ensemble')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byB148tajOCc",
        "outputId": "396c822c-8432-4f69-ad12-1ec4fdffd835"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 4s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 5s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29084464/29084464 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_model1 = VGG16(weights='imagenet', include_top=False)\n",
        "model1 = create_model(base_model1)\n",
        "\n",
        "base_model2 = ResNet50(weights='imagenet', include_top=False)\n",
        "model2 = create_model(base_model2)\n",
        "\n",
        "base_model3 = DenseNet121(weights='imagenet', include_top=False)\n",
        "model3 = create_model(base_model3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5Oq0k-77jOCc"
      },
      "outputs": [],
      "source": [
        "model1.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model2.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model3.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6xZU4R0jOCc",
        "outputId": "cf7ddce3-9eee-45c7-dbe6-00ba7de5260c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "71/71 [==============================] - 80s 784ms/step - loss: 1.1455 - accuracy: 0.6040 - val_loss: 0.8567 - val_accuracy: 0.7293\n",
            "Epoch 2/10\n",
            "71/71 [==============================] - 48s 680ms/step - loss: 0.7562 - accuracy: 0.8004 - val_loss: 0.6265 - val_accuracy: 0.8467\n",
            "Epoch 3/10\n",
            "71/71 [==============================] - 47s 664ms/step - loss: 0.5909 - accuracy: 0.8680 - val_loss: 0.5619 - val_accuracy: 0.8680\n",
            "Epoch 4/10\n",
            "71/71 [==============================] - 46s 637ms/step - loss: 0.5557 - accuracy: 0.8724 - val_loss: 0.5948 - val_accuracy: 0.8453\n",
            "Epoch 5/10\n",
            "71/71 [==============================] - 45s 621ms/step - loss: 0.4445 - accuracy: 0.9058 - val_loss: 0.5065 - val_accuracy: 0.8787\n",
            "Epoch 6/10\n",
            "71/71 [==============================] - 46s 644ms/step - loss: 0.4168 - accuracy: 0.9107 - val_loss: 0.6280 - val_accuracy: 0.8400\n",
            "Epoch 7/10\n",
            "71/71 [==============================] - 46s 646ms/step - loss: 0.3325 - accuracy: 0.9360 - val_loss: 0.4834 - val_accuracy: 0.8827\n",
            "Epoch 8/10\n",
            "71/71 [==============================] - 45s 637ms/step - loss: 0.3181 - accuracy: 0.9373 - val_loss: 0.4325 - val_accuracy: 0.9160\n",
            "Epoch 9/10\n",
            "71/71 [==============================] - 47s 666ms/step - loss: 0.2974 - accuracy: 0.9493 - val_loss: 0.3953 - val_accuracy: 0.9133\n",
            "Epoch 10/10\n",
            "71/71 [==============================] - 46s 640ms/step - loss: 0.2585 - accuracy: 0.9533 - val_loss: 0.3340 - val_accuracy: 0.9240\n",
            "Epoch 1/10\n",
            "71/71 [==============================] - 85s 631ms/step - loss: 0.8218 - accuracy: 0.8498 - val_loss: 1.5927 - val_accuracy: 0.3147\n",
            "Epoch 2/10\n",
            "71/71 [==============================] - 43s 600ms/step - loss: 0.5579 - accuracy: 0.9604 - val_loss: 1.9312 - val_accuracy: 0.3333\n",
            "Epoch 3/10\n",
            "71/71 [==============================] - 43s 601ms/step - loss: 0.5002 - accuracy: 0.9764 - val_loss: 2.4928 - val_accuracy: 0.3333\n",
            "Epoch 4/10\n",
            "71/71 [==============================] - 43s 597ms/step - loss: 0.4644 - accuracy: 0.9862 - val_loss: 3.7161 - val_accuracy: 0.3373\n",
            "Epoch 5/10\n",
            "71/71 [==============================] - 42s 594ms/step - loss: 0.4620 - accuracy: 0.9853 - val_loss: 3.2396 - val_accuracy: 0.3947\n",
            "Epoch 6/10\n",
            "71/71 [==============================] - 42s 596ms/step - loss: 0.4585 - accuracy: 0.9782 - val_loss: 3.6439 - val_accuracy: 0.3400\n",
            "Epoch 7/10\n",
            "71/71 [==============================] - 42s 590ms/step - loss: 0.4348 - accuracy: 0.9880 - val_loss: 4.1784 - val_accuracy: 0.3267\n",
            "Epoch 8/10\n",
            "71/71 [==============================] - 42s 594ms/step - loss: 0.4178 - accuracy: 0.9862 - val_loss: 2.9008 - val_accuracy: 0.5307\n",
            "Epoch 9/10\n",
            "71/71 [==============================] - 42s 593ms/step - loss: 0.4063 - accuracy: 0.9858 - val_loss: 3.1246 - val_accuracy: 0.5773\n",
            "Epoch 10/10\n",
            "71/71 [==============================] - 42s 589ms/step - loss: 0.3911 - accuracy: 0.9884 - val_loss: 2.1240 - val_accuracy: 0.6280\n",
            "Epoch 1/10\n",
            "71/71 [==============================] - 119s 691ms/step - loss: 0.7014 - accuracy: 0.8756 - val_loss: 0.5098 - val_accuracy: 0.9440\n",
            "Epoch 2/10\n",
            "71/71 [==============================] - 42s 580ms/step - loss: 0.4217 - accuracy: 0.9733 - val_loss: 0.4779 - val_accuracy: 0.9493\n",
            "Epoch 3/10\n",
            "71/71 [==============================] - 43s 605ms/step - loss: 0.3548 - accuracy: 0.9813 - val_loss: 0.4315 - val_accuracy: 0.9547\n",
            "Epoch 4/10\n",
            "71/71 [==============================] - 44s 613ms/step - loss: 0.3177 - accuracy: 0.9849 - val_loss: 0.4041 - val_accuracy: 0.9600\n",
            "Epoch 5/10\n",
            "71/71 [==============================] - 44s 613ms/step - loss: 0.2842 - accuracy: 0.9884 - val_loss: 0.5288 - val_accuracy: 0.9093\n",
            "Epoch 6/10\n",
            "71/71 [==============================] - 42s 594ms/step - loss: 0.2631 - accuracy: 0.9884 - val_loss: 0.3422 - val_accuracy: 0.9573\n",
            "Epoch 7/10\n",
            "71/71 [==============================] - 44s 615ms/step - loss: 0.2381 - accuracy: 0.9924 - val_loss: 0.3738 - val_accuracy: 0.9573\n",
            "Epoch 8/10\n",
            "71/71 [==============================] - 42s 594ms/step - loss: 0.2499 - accuracy: 0.9849 - val_loss: 0.4147 - val_accuracy: 0.9440\n",
            "Epoch 9/10\n",
            "71/71 [==============================] - 42s 590ms/step - loss: 0.2151 - accuracy: 0.9938 - val_loss: 0.3677 - val_accuracy: 0.9533\n",
            "Epoch 10/10\n",
            "71/71 [==============================] - 43s 599ms/step - loss: 0.1995 - accuracy: 0.9956 - val_loss: 0.3627 - val_accuracy: 0.9507\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7db605a1f220>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "model1.fit(train_generator, validation_data=validation_generator, epochs=10)\n",
        "model2.fit(train_generator, validation_data=validation_generator, epochs=10)\n",
        "model3.fit(train_generator, validation_data=validation_generator, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PjFac2d7wnH1"
      },
      "outputs": [],
      "source": [
        "models = [model1, model2, model3]\n",
        "model_input = tf.keras.layers.Input(shape=(224, 224, 3))\n",
        "ensemble_model = ensemble(models, model_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "EvHAkvX1wo-N"
      },
      "outputs": [],
      "source": [
        "model1.save_weights('model1_weights2.h5')\n",
        "model2.save_weights('model2_weights2.h5')\n",
        "model3.save_weights('model3_weights2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MAtveSBAw2v1"
      },
      "outputs": [],
      "source": [
        "ensemble_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1-MPOt5w9fm",
        "outputId": "a7cc6e80-d3e5-4233-d525-f848c0b816b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 12s 311ms/step - loss: 0.9370 - accuracy: 0.9480\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9370113015174866, 0.9480000138282776]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "ensemble_model.evaluate(validation_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "34-lzk4WxKmO"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import image\n",
        "\n",
        "image_path = 'cannoli.jpg'\n",
        "img = image.load_img(image_path, target_size=(224, 224))\n",
        "img = image.img_to_array(img)\n",
        "img = np.expand_dims(img, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMSFOZ0axpkm",
        "outputId": "36116252-eed2-4cf8-acdb-dd1026a04396"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        }
      ],
      "source": [
        "prediction = ensemble_model.predict(img)\n",
        "p1 = model1.predict(img)\n",
        "p2 = model2.predict(img)\n",
        "p3 = model2.predict(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4HAVdPSxyft",
        "outputId": "827ff143-d96c-4c78-ecac-ce2b18b6641f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[3.3333334e-01, 6.6666669e-01, 1.2032221e-22]], dtype=float32),\n",
              " array([[0., 1., 0.]], dtype=float32),\n",
              " array([[0., 1., 0.]], dtype=float32),\n",
              " array([[0., 1., 0.]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "prediction, p1, p2 ,p3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1Pw8HfTx4YX",
        "outputId": "bdb93b61-e35e-404f-9d31-76dcc1b3770b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cannoli\n",
            "cannoli\n",
            "cannoli\n",
            "cannoli\n"
          ]
        }
      ],
      "source": [
        "print(class_to_category[int(np.argmax(prediction, axis=1))])\n",
        "print(class_to_category[int(np.argmax(p1, axis=1))])\n",
        "print(class_to_category[int(np.argmax(p2, axis=1))])\n",
        "print(class_to_category[int(np.argmax(p3, axis=1))])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}